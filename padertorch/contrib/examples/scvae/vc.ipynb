{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from padertorch.contrib.examples.scvae.model import SCVAE\n",
    "from padertorch.contrib.examples.scvae.data import Transform\n",
    "from paderbox.database.timit import Timit\n",
    "from paderbox.database.librispeech import LibriSpeech\n",
    "import numpy as np\n",
    "import torch\n",
    "from paderbox.visualization import plot\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dir = '/net/vol/ebbers/exp/scvae-training/2019-06-16-21-00-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvae = SCVAE.from_storage_dir(storage_dir=storage_dir, config_name='1/config.json', checkpoint_name='ckpt_latest.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Timit()\n",
    "transform = Transform(storage_dir=storage_dir)\n",
    "transform.initialize_norm()\n",
    "transform.initialize_labels()\n",
    "ds = db.get_dataset('train')\n",
    "\n",
    "#def fix_speaker_id(example):\n",
    "#    example['speaker_id'] = example['speaker_id'].split('-')[0]\n",
    "#    return example\n",
    "#ds = ds.map(fix_speaker_id)\n",
    "\n",
    "ds = ds.map(\n",
    "    transform.read_audio\n",
    ").map(\n",
    "    transform.extract_features\n",
    ").map(\n",
    "    transform.normalize\n",
    ").map(\n",
    "    transform.encode_labels\n",
    ")\n",
    "mean, std = transform.moments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = ds[100]\n",
    "example2 = ds[3603]\n",
    "print(example1['log_mel'].shape)\n",
    "print(example2['log_mel'].shape)\n",
    "print(example1['speaker_id'], example2['speaker_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec1 = transform.mel_transform.inverse(std*example1['log_mel'] + mean)\n",
    "print(spec1.shape)\n",
    "spec2 = transform.mel_transform.inverse(std*example2['log_mel'] + mean)\n",
    "print(spec2.shape)\n",
    "plot.spectrogram(spec1[0])\n",
    "plot.spectrogram(spec2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1 = transform.stft.griffin_lim(np.sqrt(spec1))\n",
    "audio2 = transform.stft.griffin_lim(np.sqrt(spec2))\n",
    "print(audio1.shape)\n",
    "print(audio2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio1, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio2, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc12 = scvae.conversion(\n",
    "    torch.from_numpy(np.moveaxis(example1['log_mel'], 1, 2).astype(np.float32)),\n",
    "    torch.Tensor(example2['speaker_id'][None]).long()\n",
    ").transpose(1, 2).cpu().data.numpy()\n",
    "vc21 = scvae.conversion(\n",
    "    torch.from_numpy(np.moveaxis(example2['log_mel'], 1, 2).astype(np.float32)),\n",
    "    torch.Tensor(example1['speaker_id'][None]).long()\n",
    ").transpose(1, 2).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec12 = transform.mel_transform.inverse(std*vc12 + mean)\n",
    "spec21 = transform.mel_transform.inverse(std*vc21 + mean)\n",
    "print(spec12.shape)\n",
    "print(spec21.shape)\n",
    "plot.spectrogram(spec12[0])\n",
    "plot.spectrogram(spec21[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio12 = transform.stft.griffin_lim(np.sqrt(spec12))\n",
    "audio21 = transform.stft.griffin_lim(np.sqrt(spec21))\n",
    "print(audio12.shape)\n",
    "print(audio21.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio12, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio21, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmmvae",
   "language": "python",
   "name": "gmmvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
